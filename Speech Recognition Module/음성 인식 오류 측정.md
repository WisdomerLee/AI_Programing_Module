음성 인식의 정확성을 측정하는 가장 일반적인 방법은 \*\*정답 텍스트(Ground Truth 또는 Reference)\*\*와 \*\*음성 인식 결과(Hypothesis)\*\*를 비교하는 것입니다.
이를 위해 특정 Python 모듈이 직접적으로 "오류 확인 모듈"이나 "정확성 측정 모듈"로 명명되어 있지는 않지만, 이러한 계산을 도와주는 라이브러리들이 있습니다.
가장 널리 사용되는 평가지표는 \*\*WER (Word Error Rate, 단어 오류율)\*\*과 \*\*CER (Character Error Rate, 문자 오류율)\*\*입니다.

-----

# 1\. `jiwer` 라이브러리

`jiwer`는 음성 인식 평가를 위한 강력하고 사용하기 쉬운 Python 라이브러리입니다. WER, CER뿐만 아니라 다양한 관련 지표를 계산할 수 있게 해줍니다.

**설치:**

```bash
pip install jiwer
```

**WER (Word Error Rate, 단어 오류율) 이란?**

WER은 정답 문장과 인식된 문장 사이의 차이를 측정합니다. 다음 세 가지 유형의 오류를 고려합니다:

  * **S (Substitutions, 대체)**: 정답 단어가 다른 단어로 잘못 인식된 경우
  * **D (Deletions, 삭제)**: 정답 단어가 누락된 경우
  * **I (Insertions, 삽입)**: 정답에 없는 단어가 추가된 경우

WER 공식은 다음과 같습니다:

$$\text{WER} = \frac{S + D + I}{N}$$

여기서 $N$은 정답 문장에 있는 총 단어 수입니다. WER은 낮을수록 좋습니다.

**CER (Character Error Rate, 문자 오류율) 이란?**

CER은 단어 대신 문자 수준에서 오류를 계산합니다. 한국어나 음절 기반 언어에서 단어 단위 분리가 모호하거나, 철자 오류 등을 더 세밀하게 보고 싶을 때 유용합니다. 계산 방식은 WER과 유사합니다.

**`jiwer` 사용 예시:**

```python
import jiwer

# 실제 정답 텍스트 (Ground Truth)
ground_truth = "안녕하세요 만나서 반갑습니다"

# 음성 인식 결과 (Hypothesis)
hypothesis = "안녕하세요 만나서 반갑습니디" # '반갑습니다' -> '반갑습니디' (대체)

# 텍스트 전처리 (선택 사항이지만 권장됨)
# jiwer는 다양한 전처리 방법을 제공합니다.
# 예: 소문자화, 구두점 제거 등
transform = jiwer.Compose([
    jiwer.ToLowerCase(),
    jiwer.RemoveMultipleSpaces(),
    jiwer.RemovePunctuation(),
    jiwer.Strip()
])

ground_truth_processed = transform(ground_truth)
hypothesis_processed = transform(hypothesis)

# WER 계산
error = jiwer.wer(ground_truth_processed, hypothesis_processed)
print(f"단어 오류율 (WER): {error:.2f}") # 소수점 2자리까지 출력

# CER 계산
char_error = jiwer.cer(ground_truth_processed, hypothesis_processed)
print(f"문자 오류율 (CER): {char_error:.2f}")

# 상세 오류 분석 (S, D, I 개수 확인)
measures = jiwer.compute_measures(ground_truth_processed, hypothesis_processed)
print(f"WER 상세: {measures['wer']:.2f}")
print(f"적중 (Hits): {measures['hits']}")
print(f"대체 (Substitutions): {measures['substitutions']}")
print(f"삭제 (Deletions): {measures['deletions']}")
print(f"삽입 (Insertions): {measures['insertions']}")

print("\n--- 다른 예시 ---")
ground_truth_2 = "오늘 날씨가 정말 좋네요"
hypothesis_2 = "오늘 날씨 정말 좋네요 빨리" # '가' 삭제, '빨리' 삽입

ground_truth_2_processed = transform(ground_truth_2)
hypothesis_2_processed = transform(hypothesis_2)

error_2 = jiwer.wer(ground_truth_2_processed, hypothesis_2_processed)
print(f"두 번째 예시 WER: {error_2:.2f}")

measures_2 = jiwer.compute_measures(ground_truth_2_processed, hypothesis_2_processed)
print(f"두 번째 예시 WER 상세: {measures_2['wer']:.2f}")
print(f"H: {measures_2['hits']}, S: {measures_2['substitutions']}, D: {measures_2['deletions']}, I: {measures_2['insertions']}")

# 오류 시각화 (어떤 단어가 어떻게 틀렸는지 보여줌)
# output_bad_examples() 는 오류가 있는 경우에만 파일이나 화면에 출력합니다.
# jiwer.visualize_alignment(output) 를 사용하면 더 상세한 시각화도 가능합니다 (별도 라이브러리 필요할 수 있음)
print("\n--- 오류 시각화 (간단) ---")
output = jiwer.process_words(ground_truth_2_processed, hypothesis_2_processed)
for ref_word, hyp_word, op_code in output.alignments[0]:
    print(f"REF: {ref_word if ref_word else '<eps>'}, HYP: {hyp_word if hyp_word else '<eps>'}, OP: {op_code}")

```

**`jiwer`의 장점:**

  * 표준적인 WER, CER 계산을 쉽게 할 수 있습니다.
  * 다양한 텍스트 정규화(normalization) 및 전처리(preprocessing) 옵션을 제공하여 일관된 비교를 가능하게 합니다. (예: 소문자 변환, 구두점 제거, 숫자 단어화 등)
  * 어떤 단어가 어떻게 잘못 인식되었는지 (대체, 삭제, 삽입) 상세 정보를 제공합니다.

-----

# 2\. `nltk` 라이브러리 (편집 거리 계산)

`nltk` (Natural Language Toolkit)는 자연어 처리를 위한 광범위한 라이브러리이며, 문자열 간의 편집 거리(Edit Distance, Levenshtein Distance)를 계산하는 기능을 포함하고 있습니다.
CER은 기본적으로 문자열 간의 Levenshtein Distance를 정규화한 값입니다. WER도 단어 리스트 간의 Levenshtein Distance로 유사하게 계산할 수 있습니다.

**설치:**

```bash
pip install nltk
```

**사용 예시 (CER과 유사한 개념):**

```python
import nltk

ground_truth = "안녕하세요 만나서 반갑습니다"
hypothesis = "안녕하세요 만나서 반갑습니디"

# CER과 유사하게 문자열 편집 거리 계산
distance = nltk.edit_distance(ground_truth, hypothesis)
cer_like = distance / len(ground_truth)

print(f"NLTK 편집 거리: {distance}")
print(f"NLTK CER 유사값: {cer_like:.2f}")

# WER과 유사하게 단어 리스트 편집 거리 계산
ground_truth_words = ground_truth.split()
hypothesis_words = hypothesis.split()

word_distance = nltk.edit_distance(ground_truth_words, hypothesis_words)
wer_like = word_distance / len(ground_truth_words)
print(f"NLTK 단어 편집 거리: {word_distance}")
print(f"NLTK WER 유사값: {wer_like:.2f}")
```

`nltk.edit_distance`는 WER/CER의 핵심 계산인 Levenshtein Distance를 제공하지만, `jiwer`처럼 STT 평가에 특화된 기능(다양한 전처리, S/D/I 상세 분석 등)은 직접 구현해야 합니다. 따라서 STT 평가에는 `jiwer`를 사용하는 것이 훨씬 편리합니다.

-----

# 3\. 음성 인식 API의 신뢰도 점수 (Confidence Score)

일부 음성 인식 API (예: Google Cloud Speech-to-Text)는 인식된 각 단어나 전체 문장에 대한 **신뢰도 점수(Confidence Score)** 를 반환합니다. 이 점수는 0과 1 사이의 값으로, API가 해당 인식이 얼마나 정확하다고 판단하는지를 나타냅니다.

  * **장점**: 정답 텍스트가 없어도 API가 자체적으로 판단한 오류 가능성을 알 수 있습니다.
  * **단점**:
      * 신뢰도 점수가 낮다고 해서 반드시 오류가 있는 것은 아니며, 높다고 해서 항상 정확한 것도 아닙니다. (즉, 완벽하지 않습니다.)
      * 모든 엔진이나 `SpeechRecognition` 라이브러리의 모든 `recognize_...()` 함수가 이 정보를 제공하는 것은 아닙니다. (예: `recognize_google()`은 단순 텍스트만 반환하지만, `recognize_google_cloud()`는 `show_all=True` 옵션을 통해 상세 정보와 신뢰도 점수를 받을 수 있습니다.)

<!-- end list -->

```python
# 예시 (Google Cloud Speech-to-Text API 사용 시)
# SpeechRecognition 라이브러리에서 recognize_google_cloud 사용 시,
# show_all=True 로 설정하면 상세 결과를 받을 수 있습니다.

# import speech_recognition as sr
# r = sr.Recognizer()
# with sr.AudioFile("audio.wav") as source:
#     audio_data = r.record(source)

# try:
#     # credentials_json은 Google Cloud API 키 JSON 파일 내용입니다.
#     response = r.recognize_google_cloud(audio_data,
#                                         credentials_json=GOOGLE_CLOUD_SPEECH_CREDENTIALS,
#                                         language='ko-KR',
#                                         show_all=True) # show_all=True 중요!
#     if response and 'alternative' in response and response['alternative']:
#         best_alternative = response['alternative'][0]
#         transcript = best_alternative.get('transcript')
#         confidence = best_alternative.get('confidence') # 전체 문장 신뢰도
#         print(f"인식 결과: {transcript}")
#         if confidence:
#             print(f"신뢰도: {confidence:.2f}")

#         # 단어별 신뢰도도 있을 수 있음 (API 응답 구조 확인 필요)
#         if 'word' in best_alternative:
#             for word_info in best_alternative['word']:
#                 print(f"  단어: {word_info.get('word')}, 신뢰도: {word_info.get('confidence')}")

# except sr.UnknownValueError:
#     print("Google Cloud Speech가 오디오를 이해할 수 없습니다.")
# except sr.RequestError as e:
#     print(f"Google Cloud Speech 서비스 요청에 실패했습니다; {e}")
```

-----

### 정확성 측정 절차 요약

1.  **데이터 준비**: 평가할 오디오 파일과 해당 오디오의 정확한 **정답 텍스트(Ground Truth)** 를 준비합니다.
2.  **음성 인식 수행**: `SpeechRecognition` 등의 모듈을 사용하여 오디오를 텍스트로 변환합니다 (Hypothesis 생성).
3.  **텍스트 정규화 (Normalization)**: `jiwer`의 전처리 기능을 사용하거나 직접 구현하여 Ground Truth와 Hypothesis 텍스트를 일관된 형태로 만듭니다. (예: 모두 소문자화, 특수문자 제거, 숫자 표기 통일 등)
4.  **평가 지표 계산**: `jiwer`를 사용하여 WER, CER 등을 계산합니다.
5.  **결과 분석**: 계산된 지표와 상세 오류(S, D, I)를 통해 인식기의 성능을 분석하고 개선 방향을 찾습니다.
