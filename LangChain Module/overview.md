# **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ê°„ì†Œí™”í•˜ê³  ê°•ë ¥í•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” í”„ë ˆì„ì›Œí¬**

ë³µì¡í•œ LLM íŒŒì´í”„ë¼ì¸ì„ ì†ì‰½ê²Œ êµ¬ì¶•
ë‹¤ì–‘í•œ ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ ë° ë„êµ¬ì™€ ì—°ë™

# Langchain í•µì‹¬ í‚¤ì›Œë“œ ë° ê°œë…

Langchainì˜ ëª¨ë“ˆì‹ êµ¬ì„± ìš”ì†Œ

## 1\. Models (ëª¨ë¸)

LLM(Large Language Model)
  * **LLMs**: í…ìŠ¤íŠ¸ ë¬¸ìì—´ì„ ì…ë ¥ë°›ì•„ í…ìŠ¤íŠ¸ ë¬¸ìì—´ì„ ë°˜í™˜í•˜ëŠ” ê¸°ë³¸ ëª¨ë¸ì…ë‹ˆë‹¤.
    ```python
    from langchain_openai import OpenAI

    # OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í•„ìš”
    llm = OpenAI(model_name="gpt-3.5-turbo-instruct")
    prompt = "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"
    response = llm.invoke(prompt)
    print(response)
    # ì¶œë ¥ ì˜ˆì‹œ: ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.
    ```
  * **Chat Models (ì±— ëª¨ë¸)**: ì±„íŒ… ë©”ì‹œì§€ ëª©ë¡ì„ ì…ë ¥ë°›ì•„ ì±„íŒ… ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•˜ëŠ” ëª¨ë¸ë¡œ, ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ì— ì í•©í•©ë‹ˆë‹¤.
    ```python
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage, SystemMessage

    # OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í•„ìš”
    chat = ChatOpenAI(model_name="gpt-4")
    messages = [
        SystemMessage(content="You are a helpful assistant that translates English to Korean."),
        HumanMessage(content="I love programming."),
    ]
    response = chat.invoke(messages)
    print(response.content)
    # ì¶œë ¥ ì˜ˆì‹œ: ì €ëŠ” í”„ë¡œê·¸ë˜ë°ì„ ì‚¬ë‘í•©ë‹ˆë‹¤.
    ```
  * **Text Embedding Models (í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸)**: í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ë¹„êµí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
    ```python
    from langchain_openai import OpenAIEmbeddings

    # OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í•„ìš”
    embeddings_model = OpenAIEmbeddings()
    text = "ì•ˆë…•í•˜ì„¸ìš”, Langchainì…ë‹ˆë‹¤."
    embedded_text = embeddings_model.embed_query(text)
    print(embedded_text[:5]) # ë²¡í„°ì˜ ì²˜ìŒ 5ê°œ ì°¨ì›ë§Œ ì¶œë ¥
    ```

-----

## 2\. Prompts (í”„ë¡¬í”„íŠ¸)

LLMì— ì „ë‹¬í•  ì…ë ¥ì„ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë„êµ¬

  * **Prompt Templates (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿)**: ì‚¬ìš©ì ì…ë ¥, ë‹¤ë¥¸ ë™ì  ì •ë³´ ë“±ì„ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ```python
    from langchain_core.prompts import PromptTemplate

    prompt_template = PromptTemplate.from_template(
        "{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"
    )
    filled_prompt = prompt_template.format(country="í”„ë‘ìŠ¤")
    print(filled_prompt)
    # ì¶œë ¥: í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?

    # LLMê³¼ í•¨ê»˜ ì‚¬ìš©
    # llm = OpenAI(model_name="gpt-3.5-turbo-instruct") # ìœ„ì—ì„œ ì •ì˜í•œ llm ì‚¬ìš© ê°€ëŠ¥
    # response = llm.invoke(filled_prompt)
    # print(response)
    ```
  * **Chat Prompt Templates (ì±— í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿)**: ì±— ëª¨ë¸ì„ ìœ„í•œ ë©”ì‹œì§€ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ```python
    from langchain_core.prompts import ChatPromptTemplate

    chat_template = ChatPromptTemplate.from_messages([
        ("system", "Translate the following from {input_language} to {output_language}."),
        ("human", "{text}")
    ])
    messages = chat_template.format_messages(
        input_language="English",
        output_language="Spanish",
        text="Hello, how are you?"
    )
    print(messages)
    # chat = ChatOpenAI(model_name="gpt-4") # ìœ„ì—ì„œ ì •ì˜í•œ chat ì‚¬ìš© ê°€ëŠ¥
    # response = chat.invoke(messages)
    # print(response.content)
    ```

-----

## 3\. Chains (ì²´ì¸)

ê°€ì¥ ê¸°ë³¸ì ì¸ êµ¬ì„± ìš”ì†Œë¡œ, ì—¬ëŸ¬ LLM í˜¸ì¶œ ë˜ëŠ” ë‹¤ë¥¸ ìœ í‹¸ë¦¬í‹°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.

  * **LLMChain**: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ LLMì„ ê²°í•©í•˜ì—¬ ê°„ë‹¨í•œ ì²´ì¸ì„ ë§Œë“­ë‹ˆë‹¤. ê°€ì¥ í”í•˜ê²Œ ì‚¬ìš©ë˜ëŠ” ì²´ì¸ì…ë‹ˆë‹¤.
    ```python
    from langchain_openai import OpenAI
    from langchain_core.prompts import PromptTemplate
    from langchain.chains import LLMChain

    # OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í•„ìš”
    llm = OpenAI(model_name="gpt-3.5-turbo-instruct")
    prompt = PromptTemplate.from_template(
        "{product}ì„ ë§Œë“œëŠ” ìƒˆë¡œìš´ íšŒì‚¬ ì´ë¦„ì„ 3ê°œ ì¶”ì²œí•´ì£¼ì„¸ìš”."
    )
    chain = LLMChain(llm=llm, prompt=prompt)
    response = chain.invoke({"product": "ì¹œí™˜ê²½ ì„¸ì œ"})
    print(response)
    # ì¶œë ¥ ì˜ˆì‹œ: {'product': 'ì¹œí™˜ê²½ ì„¸ì œ', 'text': '\n\n1. ì—ì½”í“¨ì–´ (EcoPure)\n2. ê·¸ë¦°ì† (GreenSoap)\n3. ë„¤ì´ì²˜í´ë¦° (NatureClean)'}
    ```
  * **Sequential Chains (ìˆœì°¨ ì²´ì¸)**: ì—¬ëŸ¬ ì²´ì¸ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ë©°, ì´ì „ ì²´ì¸ì˜ ì¶œë ¥ì„ ë‹¤ìŒ ì²´ì¸ì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

-----

## 4\. Indexes (ì¸ë±ìŠ¤) & Retrievers (ë¦¬íŠ¸ë¦¬ë²„)

LLMì´ ì™¸ë¶€ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. \*\*RAG (Retrieval Augmented Generation)\*\*ì˜ í•µì‹¬ ìš”ì†Œì…ë‹ˆë‹¤.

  * **Document Loaders (ë¬¸ì„œ ë¡œë”)**: í…ìŠ¤íŠ¸ íŒŒì¼, PDF, ì›¹ í˜ì´ì§€ ë“± ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    ```python
    from langchain_community.document_loaders import TextLoader

    loader = TextLoader("./my_document.txt") # ì˜ˆì‹œ íŒŒì¼ ê²½ë¡œ
    # documents = loader.load()
    # print(documents[0].page_content[:100]) # ë¬¸ì„œ ë‚´ìš©ì˜ ì²˜ìŒ 100ì ì¶œë ¥
    ```
    (ì‹¤í–‰í•˜ë ¤ë©´ `my_document.txt` íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.)
  * **Text Splitters (í…ìŠ¤íŠ¸ ë¶„í• ê¸°)**: ê¸´ ë¬¸ì„œë¥¼ LLMì´ ì²˜ë¦¬í•˜ê¸° ì¢‹ì€ ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    ```python
    from langchain_text_splitters import CharacterTextSplitter

    # text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
    # texts = text_splitter.split_documents(documents) # ìœ„ì—ì„œ ë¡œë“œí•œ documents ì‚¬ìš©
    # print(len(texts))
    ```
  * **Vector Stores (ë²¡í„° ìŠ¤í† ì–´)**: í…ìŠ¤íŠ¸ ì²­í¬ì˜ ì„ë² ë”©(ìˆ«ì ë²¡í„° í‘œí˜„)ì„ ì €ì¥í•˜ê³  ê²€ìƒ‰í•©ë‹ˆë‹¤. (ì˜ˆ: FAISS, ChromaDB, Pinecone)
    ```python
    from langchain_openai import OpenAIEmbeddings
    from langchain_community.vectorstores import FAISS

    # embeddings = OpenAIEmbeddings() # ìœ„ì—ì„œ ì •ì˜í•œ embeddings_model ì‚¬ìš© ê°€ëŠ¥
    # # texts ê°ì²´ê°€ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì • (TextSplitterë¥¼ í†µí•´ ìƒì„±)
    # # vectorstore = FAISS.from_documents(texts, embeddings)
    ```
  * **Retrievers (ë¦¬íŠ¸ë¦¬ë²„)**: ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ```python
    # retriever = vectorstore.as_retriever()
    # query = "Langchainì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    # relevant_docs = retriever.invoke(query)
    # print(relevant_docs[0].page_content)
    ```

RAGë¥¼ í™œìš©í•œ ì²´ì¸ (ì˜ˆ: `RetrievalQA`):

```python
from langchain.chains import RetrievalQA
# llm, retrieverê°€ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •

# qa_chain = RetrievalQA.from_chain_type(
#     llm=llm,
#     chain_type="stuff", # ë‹¤ë¥¸ ì²´ì¸ íƒ€ì…: "map_reduce", "refine", "map_rerank"
#     retriever=retriever
# )
# query = "ë‚´ ë¬¸ì„œì—ì„œ Langchainì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜."
# result = qa_chain.invoke({"query": query})
# print(result["result"])
```

-----

## 5\. Memory (ë©”ëª¨ë¦¬)

ì²´ì¸ì´ë‚˜ ì—ì´ì „íŠ¸ê°€ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ "ê¸°ì–µ"í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

  * **ConversationBufferMemory**: ëŒ€í™”ì˜ ì „ì²´ ê¸°ë¡ì„ ë²„í¼ì— ì €ì¥í•©ë‹ˆë‹¤.
    ```python
    from langchain.memory import ConversationBufferMemory
    from langchain_openai import OpenAI
    from langchain.chains import LLMChain
    from langchain_core.prompts import PromptTemplate

    # OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í•„ìš”
    llm = OpenAI(model_name="gpt-3.5-turbo-instruct")
    # ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    template = """You are a nice chatbot having a conversation with a human.

    Previous conversation:
    {chat_history}

    New human question: {question}
    Response:"""
    prompt = PromptTemplate.from_template(template)

    # ConversationBufferMemoryëŠ” "chat_history"ë¼ëŠ” ì…ë ¥ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    memory = ConversationBufferMemory(memory_key="chat_history")

    conversation = LLMChain(
        llm=llm,
        prompt=prompt,
        verbose=True, # ì‹¤í–‰ ê³¼ì • ì¶œë ¥
        memory=memory
    )

    # ì²« ë²ˆì§¸ ëŒ€í™”
    response1 = conversation.invoke({"question": "ì œ ì´ë¦„ì€ í™ê¸¸ë™ì…ë‹ˆë‹¤."})
    print(response1['text'])

    # ë‘ ë²ˆì§¸ ëŒ€í™” (ì´ì „ ëŒ€í™” ë‚´ìš©ì´ memoryì— ì €ì¥ë˜ì–´ í™œìš©ë¨)
    response2 = conversation.invoke({"question": "ì œ ì´ë¦„ì„ ê¸°ì–µí•˜ì‹œë‚˜ìš”?"})
    print(response2['text'])
    # ì¶œë ¥ ì˜ˆì‹œ: ë„¤, í™ê¸¸ë™ë‹˜ì´ë¼ê³  ê¸°ì–µí•©ë‹ˆë‹¤.
    ```

-----

## 6\. Agents (ì—ì´ì „íŠ¸)

LLMì´ ì–´ë–¤ \*\*ë„êµ¬(Tools)\*\*ë¥¼ ì‚¬ìš©í• ì§€, ì–´ë–¤ ìˆœì„œë¡œ ì‚¬ìš©í• ì§€, ê·¸ë¦¬ê³  ê·¸ ê²°ê³¼ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í• ì§€ ìŠ¤ìŠ¤ë¡œ ê²°ì •í•˜ë„ë¡ í•˜ëŠ” ê°•ë ¥í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤. LLMì„ ì¶”ë¡  ì—”ì§„ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

  * **Tools (ë„êµ¬)**: ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íŠ¹ì • ê¸°ëŠ¥ì…ë‹ˆë‹¤. (ì˜ˆ: êµ¬ê¸€ ê²€ìƒ‰, ê³„ì‚°ê¸°, ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ë“±)
  * **Agent Executor (ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°)**: ì—ì´ì „íŠ¸ì™€ ë„êµ¬ë“¤ì„ ë°›ì•„ ì‹¤ì œë¡œ ì‹¤í–‰í•˜ëŠ” ëŸ°íƒ€ì„ì…ë‹ˆë‹¤.

<!-- end list -->

```python
from langchain_openai import OpenAI
from langchain.agents import load_tools, initialize_agent, AgentType
from langchain_community.tools import DuckDuckGoSearchRun # SerpAPI ëŒ€ì‹  DuckDuckGo ì‚¬ìš©

# OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í•„ìš”
llm = OpenAI(model_name="gpt-3.5-turbo-instruct", temperature=0)

# ë„êµ¬ ë¡œë“œ (DuckDuckGo ê²€ìƒ‰ ë„êµ¬)
# tools = load_tools(["ddg-search"], llm=llm) # ì´ì „ ë°©ì‹
search = DuckDuckGoSearchRun()
tools = [search]


# ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
# ZERO_SHOT_REACT_DESCRIPTION: ìƒí™©ì— ë”°ë¼ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ LLMì´ ê²°ì •
agent = initialize_agent(
    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True
)

# ì—ì´ì „íŠ¸ ì‹¤í–‰
question = "ì˜¤ëŠ˜ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?"
response = agent.invoke({"input": question})
print(response["output"])
# ì¶œë ¥ ì˜ˆì‹œ: (ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¼ ë‹¤ë¦„) ì˜¤ëŠ˜ ì„œìš¸ì˜ ë‚ ì”¨ëŠ” [ë‚ ì”¨ ì •ë³´]ì…ë‹ˆë‹¤.
```

**ì°¸ê³ **: `load_tools`ì—ì„œ `serpapi`ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ `SERPAPI_API_KEY` í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì˜ˆì‹œì—ì„œëŠ” ë¬´ë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ `DuckDuckGoSearchRun`ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

-----

## Langchainì˜ ì¥ì  ğŸ‘

  * **ëª¨ë“ˆì„± ë° ìœ ì—°ì„±**: í•„ìš”í•œ êµ¬ì„± ìš”ì†Œë§Œ ê°€ì ¸ì™€ ì¡°í•©í•˜ì—¬ ë§ì¶¤í˜• ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•ì´ ìš©ì´í•©ë‹ˆë‹¤.
  * **ë‹¤ì–‘í•œ LLM ì§€ì›**: OpenAI ëª¨ë¸ë¿ë§Œ ì•„ë‹ˆë¼ Hugging Face ë“± ë‹¤ì–‘í•œ LLMê³¼ ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  * **í’ë¶€í•œ ìƒíƒœê³„**: ë¬¸ì„œ ë¡œë”, ë²¡í„° ìŠ¤í† ì–´, ì—ì´ì „íŠ¸ ë„êµ¬ ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì´ ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆê±°ë‚˜ ì‰½ê²Œ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.
  * **í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°**: ì§€ì†ì ì¸ ì—…ë°ì´íŠ¸ì™€ ì‚¬ìš©ì ì§€ì›ì´ í™œë°œí•©ë‹ˆë‹¤.
  * **ë³µì¡í•œ ì‘ì—… ë‹¨ìˆœí™”**: RAG, ì—ì´ì „íŠ¸ ë“± ê³ ê¸‰ ê¸°ëŠ¥ì„ ë¹„êµì  ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë„ë¡ ì¶”ìƒí™” ìˆ˜ì¤€ì„ ì œê³µí•©ë‹ˆë‹¤.

-----
